# Configuration for Mini-Evolve

current_problem_directory: "problems/matrix_multiplication_direct" # Specifies the active problem

llm:
  provider: "ollama_local" # Indicates local Ollama
  model_name: "gemma3:27b" # Your specific Ollama model
  # model_name: "qwen3:30b-a3b"
  base_url: "http://10.1.1.28:11434/v1" # Your Ollama server base URL
  api_key: "ollama" # Placeholder, as per Ollama local setups
  temperature: 0.7
  max_tokens: 38912
  timeout_seconds: 3600 # Timeout for LLM API requests

evolution_loop:
  population_size: 50 # This is more of a target/max, actual size managed by DB
  num_generations: 5 # Reduced for quick testing initially
  num_children_per_parent: 2
  top_k_parents_pool: 10 # Select parents from the top K unique programs in DB
  num_parents_to_select: 3 # How many parents to pick from that pool

database:
  type: "sqlite" # "in_memory" or "sqlite"
  path: "db/program_database.db" # Path for SQLite DB

logging:
  level: "INFO" # DEBUG, INFO, WARNING, ERROR
  file: "log/evolution.log" 