# Configuration for Mini-Evolve

current_problem_directory: "problems/matrix_multiplication_direct" # Specifies the active problem

llm:
  provider: "openrouter" # Switched to openrouter
  # provider: "ollama_local" # Indicates local Ollama
  # model_name: "qwen3:30b-a3b" # Ollama model
  # base_url: "http://10.1.1.28:11434/v1" # Your Ollama server base URL
  # api_key: # Optional: Only if your Ollama instance is configured with authentication. Often not needed for local.

  # OpenRouter Configuration
  # model_name: "deepseek/deepseek-r1:free" # Example model, you can change this
  model_name: "google/gemini-2.5-pro-preview" # Example model, you can change this
  base_url: "https://openrouter.ai/api/v1" # Fixed for OpenRouter
  api_key_env_var: "OPENROUTER_API_KEY" # Environment variable holding your OpenRouter API key
  # Optional headers for OpenRouter ranking
  http_referer: "localhost" # Replace with your actual site URL or remove if not needed
  x_title: "Mini-Evolve" # Replace with your actual site name or remove if not needed
  
  temperature: 0.7
  max_tokens: 1000000 # Gemini
  # max_tokens: 160000 # Note: OpenRouter models have their own max token limits, ensure this is compatible or adjust per model
  timeout_seconds: 3600 # Timeout for LLM API requests

evolution_loop:
  population_size: 50 # This is more of a target/max, actual size managed by DB
  num_generations: 5 # Reduced for quick testing initially
  num_children_per_parent: 2
  top_k_parents_pool: 10 # Select parents from the top K unique programs in DB
  num_parents_to_select: 3 # How many parents to pick from that pool

database:
  type: "sqlite" # "in_memory" or "sqlite"
  path: "db/program_database.db" # Path for SQLite DB

logging:
  level: "DEBUG" # DEBUG, INFO, WARNING, ERROR
  file: "log/evolution.log" 